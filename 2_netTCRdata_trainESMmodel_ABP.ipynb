{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook assumes that you have extracted the embeddings (using the procedure mentioned in the 0_ESM_Embeddings_Extractor.ipynb notebook) and have stored them in a zipped format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5886,
     "status": "ok",
     "timestamp": 1671309022573,
     "user": {
      "displayName": "Shashank Yadav",
      "userId": "00457113104975153711"
     },
     "user_tz": 420
    },
    "id": "W4tHaAWVgePz"
   },
   "outputs": [],
   "source": [
    "#### unzip train\n",
    "!unzip -q <path_to_train_cdr3a.zip> -d  train_cdr3a\n",
    "!unzip -q <path_to_train_cdr3b.zip> -d  train_cdr3b\n",
    "!unzip -q <path_to_train_peptide.zip -d train_peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3280,
     "status": "ok",
     "timestamp": 1671309025850,
     "user": {
      "displayName": "Shashank Yadav",
      "userId": "00457113104975153711"
     },
     "user_tz": 420
    },
    "id": "lZxAwAWTnHu1"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Layer,Input, Dense, Dropout, Activation, Concatenate, Flatten, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2,l1\n",
    "from tensorflow.keras.optimizers import SGD,Adam,RMSprop\n",
    "#from tensorflow.compat.v1 import InteractiveSession\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow.keras.metrics\n",
    "####import tensorflow_addons as tfa not required\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import sklearn\n",
    "import os\n",
    "from natsort import natsorted\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1671309025851,
     "user": {
      "displayName": "Shashank Yadav",
      "userId": "00457113104975153711"
     },
     "user_tz": 420
    },
    "id": "_GVGvx6AiBtc"
   },
   "outputs": [],
   "source": [
    "\n",
    "path_train_cdr3a = <'path_to_train_cdr3a_embeddings'>                  # Example ./train_cdr3a\n",
    "path_train_cdr3b = <'path_to_train_cdr3b_embeddings'>                  # Example ./train_cdr3b\n",
    "path_train_pepti = <'path_to_train_peptide_embeddings'>                # Example ./train_peptide\n",
    "\n",
    "mat_cdr3a = os.listdir(path_train_cdr3a) \n",
    "mat_cdr3b = os.listdir(path_train_cdr3b) \n",
    "mat_pepti = os.listdir(path_train_pepti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## natsort is used to order the pairs as they appear in the .csv; this would be helpful later to map the pairs with their respective labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 577,
     "status": "ok",
     "timestamp": 1671309031835,
     "user": {
      "displayName": "Shashank Yadav",
      "userId": "00457113104975153711"
     },
     "user_tz": 420
    },
    "id": "3jeOYjgmiSIq"
   },
   "outputs": [],
   "source": [
    "###train\n",
    "mat_cdr3a = natsorted(mat_cdr3a)\n",
    "mat_cdr3b = natsorted(mat_cdr3b)\n",
    "mat_pepti = natsorted(mat_pepti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1671309038345,
     "user": {
      "displayName": "Shashank Yadav",
      "userId": "00457113104975153711"
     },
     "user_tz": 420
    },
    "id": "ccDUWNR1lwAL"
   },
   "source": [
    "## the following step extracts the embeddings and stores in a numpy matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15785,
     "status": "ok",
     "timestamp": 1671309054127,
     "user": {
      "displayName": "Shashank Yadav",
      "userId": "00457113104975153711"
     },
     "user_tz": 420
    },
    "id": "sTi1NqVtjBDL",
    "outputId": "12d36653-430c-4f89-f4d9-2bf73c91ea2c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16464/16464 [00:15<00:00, 1063.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# ESM\n",
    "orig_matmat_cdr3a = np.zeros((samples,1280))\n",
    "orig_matmat_cdr3b = np.zeros((samples,1280))\n",
    "orig_matmat_pepti = np.zeros((samples,1280))\n",
    "\n",
    "\n",
    "### load train samples \n",
    "\n",
    "for i in tqdm(range(samples)):\n",
    "\n",
    "  x = torch.load(path_train_cdr3a+mat_cdr3a[i])['mean_representations'][33]\n",
    "  orig_matmat_cdr3a[i] = x\n",
    "\n",
    "  y = torch.load(path_train_cdr3b+mat_cdr3b[i])['mean_representations'][33]\n",
    "  orig_matmat_cdr3b[i] = y\n",
    "\n",
    "  z = torch.load(path_train_pepti+mat_pepti[i])['mean_representations'][33]\n",
    "  orig_matmat_pepti[i] = z\n",
    "\n",
    "### load train samples \n",
    "\n",
    "# for i in tqdm(range(samples)):\n",
    "\n",
    "#   orig_matmat_cdr3a[i] = np.load(path_train_cdr3a+mat_cdr3a[i])\n",
    "#   orig_matmat_cdr3b[i] = np.load(path_train_cdr3b+mat_cdr3b[i])\n",
    "#   orig_matmat_pepti[i] = np.load(path_train_pepti+mat_pepti[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load *.csv files for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1671309054127,
     "user": {
      "displayName": "Shashank Yadav",
      "userId": "00457113104975153711"
     },
     "user_tz": 420
    },
    "id": "JKaFIojUmZjB"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(<path_to_csv_file_with_labels>)\n",
    "y_train = df_train['binder'].values\n",
    "orig_y_train = y_train.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 206,
     "status": "ok",
     "timestamp": 1671309220206,
     "user": {
      "displayName": "Shashank Yadav",
      "userId": "00457113104975153711"
     },
     "user_tz": 420
    },
    "id": "vdetXfGzl8FE"
   },
   "outputs": [],
   "source": [
    "### model\n",
    "def clear_sess():\n",
    "  try:\n",
    "    del model \n",
    "    del history \n",
    "  except:\n",
    "    pass\n",
    "  from tensorflow.keras import backend as K\n",
    "  K.clear_session()\n",
    "  import gc\n",
    "  gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "  return None\n",
    "\n",
    "\n",
    "def keras_mcc(y_true, y_pred):\n",
    "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    tn = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)))\n",
    "\n",
    "    num = tp * tn - fp * fn\n",
    "    den = (tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)\n",
    "    return num / K.sqrt(den + K.epsilon())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzxZPO0jmA5e"
   },
   "source": [
    "## model MLP for CDR3b and peptide || CDR3a and peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dzxZPO0jmA5e"
   },
   "outputs": [],
   "source": [
    "clear_sess()\n",
    "#input_1\n",
    "\n",
    "\n",
    "input_1 = Input(shape = (1280,), name='i_1')\n",
    "dense1_1 = Dense(128, activation = 'elu')(input_1)\n",
    "bn1_1 = BatchNormalization()(dense1_1)\n",
    "drop_1 = Dropout(0.5)(bn1_1)\n",
    "\n",
    "#input_2\n",
    "input_2 = Input(shape = (1280,), name='i_2')\n",
    "dense2_1 = Dense(128, activation = 'elu')(input_2)\n",
    "bn2_1 = BatchNormalization()(dense2_1)\n",
    "drop_2 = Dropout(0.5)(bn2_1)\n",
    "\n",
    "# #input_3\n",
    "# input_3 = Input(shape = (1024,), name='i_3')\n",
    "# dense3_1 = Dense(512, activation = 'relu')(input_3)\n",
    "# bn3_1 = BatchNormalization()(dense3_1)\n",
    "# drop_3 = Dropout(0.5)(bn3_1)\n",
    "\n",
    "\n",
    "# concatenate\n",
    "##concat   = Concatenate()([dense1_1, dense2_1])\n",
    "##concat   = Concatenate()([bn1_1, bn2_1])\n",
    "concat   = Concatenate()([drop_1,drop_2])\n",
    "fc_1   = Dense(512, activation = 'relu')(concat)\n",
    "drop_4 = Dropout(0.5)(fc_1)\n",
    "fc_2   = Dense(256, activation = 'relu')(drop_4)\n",
    "#classification output- TCR-Peptide Binding yes/no\n",
    "output  = Dense(1, activation = 'sigmoid')(fc_2)\n",
    " \n",
    "# create model with two inputs\n",
    "model = Model(inputs=[input_1,input_2], outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2Q70DW7v8z_"
   },
   "source": [
    "## model MLP ## for CDR3a with CDR3b and peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N2Q70DW7v8z_"
   },
   "outputs": [],
   "source": [
    "clear_sess()\n",
    "#input_1\n",
    "\n",
    "input_1 = Input(shape = (1280,), name='i_1')\n",
    "dense1_1 = Dense(128, activation = 'relu')(input_1)\n",
    "bn1_1 = BatchNormalization()(dense1_1)\n",
    "\n",
    "#input_2\n",
    "input_2 = Input(shape = (1280,), name='i_2')\n",
    "dense2_1 = Dense(128, activation = 'relu')(input_2)\n",
    "bn2_1 = BatchNormalization()(dense2_1)\n",
    "\n",
    "#input_3\n",
    "input_3 = Input(shape = (1280,), name='i_3')\n",
    "dense3_1 = Dense(128, activation = 'relu')(input_3)\n",
    "bn3_1 = BatchNormalization()(dense3_1)\n",
    " \n",
    "# concatenate\n",
    "##concat   = Concatenate()([dense1_1, dense2_1])\n",
    "concat   = Concatenate()([bn1_1, bn2_1, bn3_1])\n",
    "fc_1   = Dense(128, activation = 'relu')(concat)\n",
    "#drop_1 = Dropout(0.5)(fc_1)\n",
    "fc_2   = Dense(128, activation = 'relu')(fc_1)\n",
    "#classification output\n",
    "output  = Dense(1, activation = 'sigmoid')(fc_2)\n",
    " \n",
    "# create model with two inputs\n",
    "model = Model(inputs=[input_1,input_2, input_3], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ovz2w6aRoNH-"
   },
   "outputs": [],
   "source": [
    "metrics_c = [tensorflow.keras.metrics.AUC(name=\"auc_roc\",curve=\"ROC\"),tensorflow.keras.metrics.AUC(name=\"auc_pr\",curve=\"PR\"),keras_mcc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LuNHZqwmoTQI"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=tensorflow.keras.optimizers.Adam(learning_rate=0.008), \n",
    "              metrics=metrics_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jOQDxmQ3qBB6"
   },
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='loss',min_delta=0,patience=10, verbose=0,mode='min',restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u2sSum9klaeb"
   },
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_keras_mcc', factor=0.99,patience=20, min_lr=0.005, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ShUY7ZOCp1Md"
   },
   "outputs": [],
   "source": [
    "checkpoint_filepath_1 = 'weights-improvement-val-auc-pr.hdf5'\n",
    "model_checkpoint_callback_1 = ModelCheckpoint(filepath=checkpoint_filepath_1,save_weights_only=False,monitor='val_auc_pr',mode='max',save_best_only=True)\n",
    "\n",
    "checkpoint_filepath_2 = 'weights-improvement-val-keras-mcc.hdf5'\n",
    "model_checkpoint_callback_2 = ModelCheckpoint(filepath=checkpoint_filepath_2,save_weights_only=False,monitor='val_keras_mcc',mode='max',save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## uncomment the following cell for running CDR3a, CDR3b, peptide model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Do3GZ7GKsUrX"
   },
   "outputs": [],
   "source": [
    "# fit the keras model on the dataset CDR3a, CDR3b, peptide\n",
    "# history=model.fit([train_cdr3a, train_cdr3b,train_pep],train_Y,\n",
    "#                   batch_size=1024, epochs=500,\n",
    "#                   validation_split=0.1,\n",
    "#                   callbacks=[model_checkpoint_callback_1, model_checkpoint_callback_2, reduce_lr ]\n",
    "#                   verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## uncomment the following cell for running CDR3b, peptide model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kRa17DQI9Cwu"
   },
   "outputs": [],
   "source": [
    "# # fit the keras model on the dataset CDR3b, peptide\n",
    "# history=model.fit([matmat_cdr3b,matmat_pepti],y_train,\n",
    "#                   batch_size=1024, epochs=500,\n",
    "#                   validation_split=0.1,\n",
    "#                   callbacks=[model_checkpoint_callback_1, model_checkpoint_callback_2, reduce_lr ]\n",
    "#                   verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## uncomment the following cell for running CDR3a, peptide model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UF5TlFXfoVzu"
   },
   "outputs": [],
   "source": [
    "# # fit the keras model on the dataset CDR3a, CDR3b, peptide\n",
    "# history=model.fit([matmat_cdr3a,matmat_pepti],y_train,\n",
    "#                   batch_size=1024, epochs=500,\n",
    "#                   verbose=0,\n",
    "#                   validation_split=0.1,\n",
    "#                   callbacks=[model_checkpoint_callback_1, model_checkpoint_callback_2, reduce_lr ]\n",
    "#                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## once the best model is trained, we can test it over the evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dyt2dq9DCnzs"
   },
   "outputs": [],
   "source": [
    "# ####model load max aucpr\n",
    "model_loaded = '/content/weights-improvement-val-auc-pr.hdf5'\n",
    "model = tensorflow.keras.models.load_model(model_loaded,compile=False)\n",
    "y_pred = model.predict([evalmatmat_cdr3a, evalmatmat_cdr3b,evalmatmat_pepti])\n",
    "#y_pred = model.predict([evalmatmat_cdr3b,evalmatmat_pepti])\n",
    "y_act = y_eval.flatten()\n",
    "y_pred= y_pred.flatten()\n",
    "y_pred_c=np.where(y_pred>0.5,1,0)\n",
    "print(roc_auc_score(y_act, y_pred),average_precision_score(y_act, y_pred),matthews_corrcoef(y_act,y_pred_c),cohen_kappa_score(y_act,y_pred_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SneM5HdV6drj"
   },
   "outputs": [],
   "source": [
    "# ####model load max mcc\n",
    "model_loaded = '/content/weights-improvement-val-keras-mcc.hdf5'\n",
    "model = tensorflow.keras.models.load_model(model_loaded,compile=False)\n",
    "y_pred = model.predict([evalmatmat_cdr3a, evalmatmat_cdr3b,evalmatmat_pepti])\n",
    "#y_pred = model.predict([evalmatmat_cdr3b,evalmatmat_pepti])\n",
    "y_act = y_eval.flatten()\n",
    "y_pred= y_pred.flatten()\n",
    "y_pred_c=np.where(y_pred>0.5,1,0)\n",
    "print(roc_auc_score(y_act, y_pred),average_precision_score(y_act, y_pred),matthews_corrcoef(y_act,y_pred_c),cohen_kappa_score(y_act,y_pred_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ibwd9SpiB6_"
   },
   "source": [
    "## once the model training process is okay, we can run it for the CV set as originally defined by the netTCR 2.0 work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_assignments = df_train['partition']\n",
    "\n",
    "# Your data and labels (replace with your own data)\n",
    "X = orig_matmat_pepti  # Your data\n",
    "y = orig_y_train  # Your labels\n",
    "\n",
    "# Number of predefined folds (assumes the folds are numbered 1, 2, 3, 4, 5)\n",
    "num_folds = 5\n",
    "\n",
    "for fold in range(1, num_folds + 1):\n",
    "    # Split data into train and test sets based on the predefined test fold\n",
    "    X_test = X[np.array(fold_assignments) == fold]\n",
    "    y_test = y[np.array(fold_assignments) == fold]\n",
    "    data_test = df_train[np.array(fold_assignments) == fold]\n",
    "\n",
    "    X_train = X[np.array(fold_assignments) != fold]\n",
    "    y_train = y[np.array(fold_assignments) != fold]\n",
    "    data_train = df_train[np.array(fold_assignments) != fold]\n",
    "\n",
    "    # Replace this with your machine learning model and evaluation code\n",
    "    # Train your model on X_train, y_train, and evaluate it on X_test, y_test\n",
    "\n",
    "    print(f\"Fold {fold}: Train {len(X_train)}, Test {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress all UserWarnings\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AB chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### this is for CV originally defined\n",
    "\n",
    "def make_data_alphabeta(orig_matmat_cdr3a, orig_matmat_cdr3b, orig_matmat_pepti, orig_y_train, fold_assignments, fold):\n",
    "\n",
    "    acti = 'gelu'\n",
    "    # print(fold)\n",
    "    matmat_cdr3a = orig_matmat_cdr3a[np.array(fold_assignments) != fold]\n",
    "    matmat_cdr3b = orig_matmat_cdr3b[np.array(fold_assignments) != fold]\n",
    "    matmat_pepti = orig_matmat_pepti[np.array(fold_assignments) != fold]\n",
    "    y_train      = orig_y_train[np.array(fold_assignments) != fold]\n",
    "    data_train = df_train[np.array(fold_assignments) != fold]\n",
    "\n",
    "    #### internal eval\n",
    "    evalmatmat_cdr3a = orig_matmat_cdr3a[np.array(fold_assignments) == fold]\n",
    "    evalmatmat_cdr3b = orig_matmat_cdr3b[np.array(fold_assignments) == fold]\n",
    "    evalmatmat_pepti = orig_matmat_pepti[np.array(fold_assignments) == fold]\n",
    "    y_eval           = orig_y_train[np.array(fold_assignments) == fold]\n",
    "    data_test = df_train[np.array(fold_assignments) == fold]\n",
    "    \n",
    "    train_input = [matmat_cdr3a,matmat_cdr3b,matmat_pepti]\n",
    "    train_output= y_train\n",
    "\n",
    "\n",
    "    test_input = [evalmatmat_cdr3a,evalmatmat_cdr3b,evalmatmat_pepti]\n",
    "    test_output= y_eval\n",
    "\n",
    "\n",
    "    #input 1\n",
    "    input_1 = Input(shape = (1280,), name='i_1')\n",
    "    dense1_1 = Dense(128, activation = acti)(input_1)\n",
    "    bn1_1 = BatchNormalization()(dense1_1)\n",
    "    drop_1 = Dropout(0.5)(bn1_1)\n",
    "\n",
    "    #input_2\n",
    "    input_2 = Input(shape = (1280,), name='i_2')\n",
    "    dense2_1 = Dense(128, activation = acti)(input_2)\n",
    "    bn2_1 = BatchNormalization()(dense2_1)\n",
    "    drop_2 = Dropout(0.5)(bn2_1)\n",
    "\n",
    "    #input_3\n",
    "    input_3 = Input(shape = (1280,), name='i_3')\n",
    "    dense3_1 = Dense(128, activation = acti)(input_3)\n",
    "    bn3_1 = BatchNormalization()(dense3_1)\n",
    "    drop_3 = Dropout(0.5)(bn3_1)\n",
    "\n",
    "    # concatenate\n",
    "    ##concat   = Concatenate()([dense1_1, dense2_1])\n",
    "    ##concat   = Concatenate()([bn1_1, bn2_1])\n",
    "    concat   = Concatenate()([drop_1,drop_2,drop_3])\n",
    "    fc_1   = Dense(256, activation = acti)(concat)\n",
    "    drop_4 = Dropout(0.5)(fc_1)\n",
    "    fc_2   = Dense(128, activation = acti)(drop_4)\n",
    "    #classification output- TCR-Peptide Binding yes/no\n",
    "    output  = Dense(1, activation = 'sigmoid')(fc_2)\n",
    "\n",
    "    # create model with two inputs\n",
    "    model = Model(inputs=[input_1,input_2, input_3], outputs=output)\n",
    "\n",
    "    return model, train_input, test_input, train_output, test_output, data_train, data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### this is for CV originally defined\n",
    "\n",
    "def make_data_beta(orig_matmat_cdr3b, orig_matmat_pepti, orig_y_train, fold_assignments, fold):\n",
    "\n",
    "    acti = 'gelu'\n",
    "    matmat_cdr3b = orig_matmat_cdr3b[np.array(fold_assignments) != fold]\n",
    "    matmat_pepti = orig_matmat_pepti[np.array(fold_assignments) != fold]\n",
    "    y_train      = orig_y_train[np.array(fold_assignments) != fold]\n",
    "    data_train = df_train[np.array(fold_assignments) != fold]\n",
    "\n",
    "    #### internal eval\n",
    "    evalmatmat_cdr3b = orig_matmat_cdr3b[np.array(fold_assignments) == fold]\n",
    "    evalmatmat_pepti = orig_matmat_pepti[np.array(fold_assignments) == fold]\n",
    "    y_eval           = orig_y_train[np.array(fold_assignments) == fold]\n",
    "    data_test = df_train[np.array(fold_assignments) == fold]\n",
    "\n",
    "    train_input = [matmat_cdr3b,matmat_pepti]\n",
    "    train_output= y_train\n",
    "\n",
    "    test_input = [evalmatmat_cdr3b,evalmatmat_pepti]\n",
    "    test_output= y_eval\n",
    "    \n",
    "    #input 1\n",
    "    input_1 = Input(shape = (1280,), name='i_1')\n",
    "    dense1_1 = Dense(128, activation = acti)(input_1)\n",
    "    bn1_1 = BatchNormalization()(dense1_1)\n",
    "    drop_1 = Dropout(0.5)(bn1_1)\n",
    "\n",
    "    #input_2\n",
    "    input_2 = Input(shape = (1280,), name='i_2')\n",
    "    dense2_1 = Dense(128, activation = acti)(input_2)\n",
    "    bn2_1 = BatchNormalization()(dense2_1)\n",
    "    drop_2 = Dropout(0.5)(bn2_1)\n",
    "\n",
    "    # concatenate\n",
    "    concat   = Concatenate()([drop_1,drop_2])\n",
    "    fc_1   = Dense(256, activation = acti)(concat)\n",
    "    drop_4 = Dropout(0.5)(fc_1)\n",
    "    fc_2   = Dense(128, activation = acti)(drop_4)\n",
    "    #classification output- TCR-Peptide Binding yes/no\n",
    "    output  = Dense(1, activation = 'sigmoid')(fc_2)\n",
    "\n",
    "    # create model with two inputs\n",
    "    model = Model(inputs=[input_1,input_2], outputs=output)\n",
    "\n",
    "    return model, train_input, test_input, train_output, test_output, data_train, data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### this is for CV originally defined\n",
    "\n",
    "def make_data_alpha(orig_matmat_cdr3a, orig_matmat_pepti, orig_y_train, fold_assignments, fold):\n",
    "\n",
    "    acti = 'gelu'\n",
    "    # print(fold)\n",
    "    matmat_cdr3a = orig_matmat_cdr3a[np.array(fold_assignments) != fold]\n",
    "    matmat_pepti = orig_matmat_pepti[np.array(fold_assignments) != fold]\n",
    "    y_train      = orig_y_train[np.array(fold_assignments) != fold]\n",
    "    data_train = df_train[np.array(fold_assignments) != fold]\n",
    "\n",
    "    #### internal eval\n",
    "    evalmatmat_cdr3a = orig_matmat_cdr3a[np.array(fold_assignments) == fold]\n",
    "    evalmatmat_pepti = orig_matmat_pepti[np.array(fold_assignments) == fold]\n",
    "    y_eval           = orig_y_train[np.array(fold_assignments) == fold]\n",
    "    data_test = df_train[np.array(fold_assignments) == fold]\n",
    "\n",
    "    train_input = [matmat_cdr3a,matmat_pepti]\n",
    "    train_output= y_train\n",
    "\n",
    "    test_input = [evalmatmat_cdr3a,evalmatmat_pepti]\n",
    "    test_output= y_eval\n",
    "    \n",
    "    #input 1\n",
    "    input_1 = Input(shape = (1280,), name='i_1')\n",
    "    dense1_1 = Dense(128, activation = acti)(input_1)\n",
    "    bn1_1 = BatchNormalization()(dense1_1)\n",
    "    drop_1 = Dropout(0.5)(bn1_1)\n",
    "\n",
    "    #input_2\n",
    "    input_2 = Input(shape = (1280,), name='i_2')\n",
    "    dense2_1 = Dense(128, activation = acti)(input_2)\n",
    "    bn2_1 = BatchNormalization()(dense2_1)\n",
    "    drop_2 = Dropout(0.5)(bn2_1)\n",
    "\n",
    "    # concatenate\n",
    "    concat   = Concatenate()([drop_1,drop_2])\n",
    "    fc_1   = Dense(256, activation = acti)(concat)\n",
    "    drop_4 = Dropout(0.5)(fc_1)\n",
    "    fc_2   = Dense(128, activation = acti)(drop_4)\n",
    "    #classification output- TCR-Peptide Binding yes/no\n",
    "    output  = Dense(1, activation = 'sigmoid')(fc_2)\n",
    "\n",
    "    # create model with two inputs\n",
    "    model = Model(inputs=[input_1,input_2], outputs=output)\n",
    "\n",
    "    return model, train_input, test_input, train_output, test_output, data_train, data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Runs - Run AB chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_assignments = df_train['partition']\n",
    "\n",
    "for fold in range(1, num_folds + 1):\n",
    "\n",
    "    clear_sess()\n",
    "    model, train_input, test_input, train_output, test_output, data_train, data_test = make_data_alphabeta(orig_matmat_cdr3a, orig_matmat_cdr3b, orig_matmat_pepti, orig_y_train, fold_assignments, fold)\n",
    "\n",
    "    print(f\"Fold {fold}: Train {train_input[0].shape}, Test {test_input[0].shape}\")\n",
    "\n",
    "    metrics_c = [tensorflow.keras.metrics.AUC(name=\"auc_pr\",curve=\"PR\"),tensorflow.keras.metrics.AUC(name=\"auc_roc\",curve=\"ROC\"),keras_mcc]\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.007), metrics=metrics_c )\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_keras_mcc', factor=0.99,patience=20, min_lr=0.005, verbose=0)\n",
    "    checkpoint_filepath_mcc = f'/content/weights/weights-improvement-{fold}-mcc.hdf5'\n",
    "    checkpoint_filepath_pr = f'/content/weights/weights-improvement-{fold}-pr.hdf5'\n",
    "    model_checkpoint_callback_mcc = ModelCheckpoint(filepath=checkpoint_filepath_mcc,save_weights_only=False,monitor='val_keras_mcc',mode='max',save_best_only=True)\n",
    "    model_checkpoint_callback_pr = ModelCheckpoint(filepath=checkpoint_filepath_pr,save_weights_only=False,monitor='val_auc_pr',mode='max',save_best_only=True)\n",
    "\n",
    "\n",
    "    history = model.fit(train_input, train_output,epochs=500,batch_size=32, verbose=0, validation_data=(test_input,test_output),\n",
    "                        callbacks=[model_checkpoint_callback_mcc,model_checkpoint_callback_pr,reduce_lr])\n",
    "\n",
    "    peplist = ['GILGFVFTL', 'GLCTLVAML', 'NLVPMVATV', 'LLFGYPVYV', 'FLYALALLL', 'RTLNAWVKV', 'IMDQVPFSV', 'KTWGQYWQV']\n",
    "    print('Loading best MCC model')\n",
    "    model_loaded = checkpoint_filepath_mcc\n",
    "    model = tensorflow.keras.models.load_model(model_loaded,compile=False)\n",
    "\n",
    "    y_pred = model.predict(test_input, verbose=0)\n",
    "    y_act = test_output.flatten()\n",
    "    y_pred= y_pred.flatten()\n",
    "    y_pred_c=np.where(y_pred>0.5,1,0)\n",
    "    print('MCC: ', matthews_corrcoef(y_act,y_pred_c), 'ROC :', roc_auc_score(y_act, y_pred), 'PR: ', average_precision_score(y_act, y_pred),  'F1:', f1_score(y_act,y_pred_c))\n",
    "    for pep in peplist:\n",
    "            y_act_pep   = y_act[data_test['peptide']  == pep]\n",
    "            y_pred_pep  = y_pred[data_test['peptide'] == pep]\n",
    "            y_pred_c_pep=y_pred_c[data_test['peptide']== pep]\n",
    "            print(f'{pep}:', 'MCC: ', matthews_corrcoef(y_act_pep,y_pred_c_pep), 'ROC :', roc_auc_score(y_act_pep, y_pred_pep), 'PR: ', average_precision_score(y_act_pep, y_pred_pep), 'F1:', f1_score(y_act_pep,y_pred_c_pep))\n",
    "\n",
    "    print('Loading best PR model')\n",
    "    model_loaded = checkpoint_filepath_pr\n",
    "    model = tensorflow.keras.models.load_model(model_loaded,compile=False)\n",
    "\n",
    "    y_pred = model.predict(test_input, verbose=0)\n",
    "    y_act = test_output.flatten()\n",
    "    y_pred= y_pred.flatten()\n",
    "    y_pred_c=np.where(y_pred>0.5,1,0)\n",
    "    print('MCC: ', matthews_corrcoef(y_act,y_pred_c), 'ROC :', roc_auc_score(y_act, y_pred), 'PR: ', average_precision_score(y_act, y_pred),  'F1:', f1_score(y_act,y_pred_c))\n",
    "\n",
    "    for pep in peplist:\n",
    "        y_act_pep   = y_act[data_test['peptide']  == pep]\n",
    "        y_pred_pep  = y_pred[data_test['peptide'] == pep]\n",
    "        y_pred_c_pep=y_pred_c[data_test['peptide']== pep]\n",
    "        print(f'{pep}:', 'MCC: ', matthews_corrcoef(y_act_pep,y_pred_c_pep), 'ROC :', roc_auc_score(y_act_pep, y_pred_pep), 'PR: ', average_precision_score(y_act_pep, y_pred_pep), 'F1:', f1_score(y_act_pep,y_pred_c_pep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model runs - B chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_assignments = df_train['partition']\n",
    "\n",
    "# Number of predefined folds (assumes the folds are numbered 1, 2, 3, 4, 5)\n",
    "num_folds = 5\n",
    "\n",
    "for fold in range(1, num_folds + 1):\n",
    "    clear_sess()\n",
    "    model, train_input, test_input, train_output, test_output, data_train, data_test = make_data_beta(orig_matmat_cdr3b, orig_matmat_pepti, orig_y_train, fold_assignments, fold)\n",
    "\n",
    "    print(f\"Fold {fold}: Train {train_input[0].shape}, Test {test_input[0].shape}\")\n",
    "\n",
    "    metrics_c = [tensorflow.keras.metrics.AUC(name=\"auc_pr\",curve=\"PR\"),tensorflow.keras.metrics.AUC(name=\"auc_roc\",curve=\"ROC\"),keras_mcc]\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.007), metrics=metrics_c )\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_keras_mcc', factor=0.99,patience=20, min_lr=0.005, verbose=0)\n",
    "    checkpoint_filepath_mcc = f'/content/weights/weights-improvement-{fold}-mcc.hdf5'\n",
    "    checkpoint_filepath_pr = f'/content/weights/weights-improvement-{fold}-pr.hdf5'\n",
    "    model_checkpoint_callback_mcc = ModelCheckpoint(filepath=checkpoint_filepath_mcc,save_weights_only=False,monitor='val_keras_mcc',mode='max',save_best_only=True)\n",
    "    model_checkpoint_callback_pr = ModelCheckpoint(filepath=checkpoint_filepath_pr,save_weights_only=False,monitor='val_auc_pr',mode='max',save_best_only=True)\n",
    "\n",
    "    history = model.fit(train_input, train_output,epochs=200,batch_size=64, verbose=0, validation_data=(test_input,test_output),\n",
    "                      callbacks=[model_checkpoint_callback_mcc,model_checkpoint_callback_roc,model_checkpoint_callback_pr,reduce_lr])\n",
    "    print('Loading best MCC model')\n",
    "    model_loaded = checkpoint_filepath_mcc\n",
    "    model = tensorflow.keras.models.load_model(model_loaded,compile=False)\n",
    "\n",
    "    y_pred = model.predict(test_input, verbose=0)\n",
    "    y_act = test_output.flatten()\n",
    "    y_pred= y_pred.flatten()\n",
    "    y_pred_c=np.where(y_pred>0.5,1,0)\n",
    "    print('MCC: ', matthews_corrcoef(y_act,y_pred_c), 'ROC :', roc_auc_score(y_act, y_pred), 'PR: ', average_precision_score(y_act, y_pred), 'F1:', f1_score(y_act,y_pred_c))\n",
    "\n",
    "    print('Loading best PR model')\n",
    "    model_loaded = checkpoint_filepath_pr\n",
    "    model = tensorflow.keras.models.load_model(model_loaded,compile=False)\n",
    "\n",
    "    y_pred = model.predict(test_input, verbose=0)\n",
    "    y_act = test_output.flatten()\n",
    "    y_pred= y_pred.flatten()\n",
    "    y_pred_c=np.where(y_pred>0.5,1,0)\n",
    "    print('MCC: ', matthews_corrcoef(y_act,y_pred_c), 'ROC :', roc_auc_score(y_act, y_pred), 'PR: ', average_precision_score(y_act, y_pred), 'F1:', f1_score(y_act,y_pred_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model runs A chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_assignments = df_train['partition']\n",
    "\n",
    "# Number of predefined folds (assumes the folds are numbered 1, 2, 3, 4, 5)\n",
    "num_folds = 5\n",
    "\n",
    "for fold in range(1, num_folds + 1):\n",
    "    clear_sess()\n",
    "    model, train_input, test_input, train_output, test_output, data_train, data_test = make_data_alpha(orig_matmat_cdr3a, orig_matmat_pepti, orig_y_train, fold_assignments, fold)\n",
    "\n",
    "    print(f\"Fold {fold}: Train {train_input[0].shape}, Test {test_input[0].shape}\")\n",
    "\n",
    "    metrics_c = [tensorflow.keras.metrics.AUC(name=\"auc_pr\",curve=\"PR\"),tensorflow.keras.metrics.AUC(name=\"auc_roc\",curve=\"ROC\"),keras_mcc]\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.007), metrics=metrics_c )\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_keras_mcc', factor=0.99,patience=20, min_lr=0.005, verbose=0)\n",
    "    checkpoint_filepath_mcc = f'/content/weights/weights-improvement-{fold}-mcc.hdf5'\n",
    "    checkpoint_filepath_pr = f'/content/weights/weights-improvement-{fold}-pr.hdf5'\n",
    "    model_checkpoint_callback_mcc = ModelCheckpoint(filepath=checkpoint_filepath_mcc,save_weights_only=False,monitor='val_keras_mcc',mode='max',save_best_only=True)\n",
    "    model_checkpoint_callback_pr = ModelCheckpoint(filepath=checkpoint_filepath_pr,save_weights_only=False,monitor='val_auc_pr',mode='max',save_best_only=True)\n",
    "\n",
    "    history = model.fit(train_input, train_output,epochs=200,batch_size=2048, verbose=0, validation_data=(test_input,test_output),\n",
    "                      callbacks=[model_checkpoint_callback_mcc,model_checkpoint_callback_roc,model_checkpoint_callback_pr,reduce_lr])\n",
    "    print('Loading best MCC model')\n",
    "    model_loaded = checkpoint_filepath_mcc\n",
    "    model = tensorflow.keras.models.load_model(model_loaded,compile=False)\n",
    "\n",
    "    y_pred = model.predict(test_input, verbose=0)\n",
    "    y_act = test_output.flatten()\n",
    "    y_pred= y_pred.flatten()\n",
    "    y_pred_c=np.where(y_pred>0.5,1,0)\n",
    "    print('MCC: ', matthews_corrcoef(y_act,y_pred_c), 'ROC :', roc_auc_score(y_act, y_pred), 'PR: ', average_precision_score(y_act, y_pred), 'F1:', f1_score(y_act,y_pred_c))\n",
    "\n",
    "    print('Loading best PR model')\n",
    "    model_loaded = checkpoint_filepath_pr\n",
    "    model = tensorflow.keras.models.load_model(model_loaded,compile=False)\n",
    "\n",
    "    y_pred = model.predict(test_input, verbose=0)\n",
    "    y_act = test_output.flatten()\n",
    "    y_pred= y_pred.flatten()\n",
    "    y_pred_c=np.where(y_pred>0.5,1,0)\n",
    "    print('MCC: ', matthews_corrcoef(y_act,y_pred_c), 'ROC :', roc_auc_score(y_act, y_pred), 'PR: ', average_precision_score(y_act, y_pred), 'F1:', f1_score(y_act,y_pred_c))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOGk9+cmAAhRreeVD5LrvMz",
   "mount_file_id": "19JctTUeCX4nplqK_SRMV59QSBTV2lfnx",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
